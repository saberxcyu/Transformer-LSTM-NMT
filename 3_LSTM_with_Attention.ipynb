{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8hqqLids73mw",
        "outputId": "e0005cd6-5f1c-48ac-8924-638593553240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Running Notebook No.3 to build a LSTM NMT with Attention.\n",
            "================================================================================\n",
            "\n",
            "1. Mounting Google Drive...\n",
            "Mounted at /content/gdrive\n",
            "\n",
            "2. Loading tokenizers and padded data...\n",
            "Done.\n",
            "\n",
            "3. Splitting data into training (70%), validation (10%), and test (20%) sets...\n",
            "Done.\n",
            "\n",
            "4. Initializing encoder and decoder models with attention...\n",
            "Done.\n",
            "\n",
            "5. Model training...\n",
            "Epoch 1, Training Loss 5.1670, Validation Loss 4.2258, Time: 2.41 min\n",
            "Epoch 2, Training Loss 3.6944, Validation Loss 3.3033, Time: 2.38 min\n",
            "Epoch 3, Training Loss 2.8646, Validation Loss 2.7413, Time: 2.38 min\n",
            "Epoch 4, Training Loss 2.3426, Validation Loss 2.4542, Time: 2.38 min\n",
            "Epoch 5, Training Loss 2.0039, Validation Loss 2.2725, Time: 2.38 min\n",
            "Epoch 6, Training Loss 1.7568, Validation Loss 2.1738, Time: 2.38 min\n",
            "Epoch 7, Training Loss 1.5678, Validation Loss 2.1037, Time: 2.38 min\n",
            "Epoch 8, Training Loss 1.4180, Validation Loss 2.0667, Time: 2.39 min\n",
            "Epoch 9, Training Loss 1.2931, Validation Loss 2.0427, Time: 2.38 min\n",
            "Epoch 10, Training Loss 1.1890, Validation Loss 2.0276, Time: 2.38 min\n",
            "Epoch 11, Training Loss 1.0986, Validation Loss 2.0349, Time: 2.40 min\n",
            "Epoch 12, Training Loss 1.0217, Validation Loss 2.0376, Time: 2.38 min\n",
            "Epoch 13, Training Loss 0.9537, Validation Loss 2.0488, Time: 2.39 min\n",
            "Epoch 14, Training Loss 0.8938, Validation Loss 2.0704, Time: 2.39 min\n",
            "Epoch 15, Training Loss 0.8394, Validation Loss 2.0893, Time: 2.38 min\n",
            "Training completed. Best model from epoch 10 with Validation Loss = 2.0276\n",
            "Best model saved to: /content/gdrive/My Drive/NMT_Data/NMT_Models/LSTM_with_attention\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model performance on test data...\n",
            "\n",
            "Test Loss: 2.0184\n",
            "Perplexity: 7.5265\n",
            "\n",
            "6. Creating a translator instance with the trained encoder and decoder (with attention)...\n",
            "Done.\n",
            "\n",
            "7. Let's use the translator on a few examples...\n",
            "Example 1\n",
            "To be translated: Êà∏ „Å´ „ÅØ Êñ∞„Åó„Åè „Éö„É≥„Ç≠ „Åå Â°ó„Å£ „Å¶ „ÅÇ„Å£ „Åü „ÄÇ\n",
            "Reference translation: there was a new coat of paint on the door\n",
            "Translator output: the door was a new paint\n",
            "BLEU Score: 13.65\n",
            "--------------------------------------------------------------------------------\n",
            "Example 2\n",
            "To be translated: Êó©„Åè Ëµ∑„Åç „Å™„Åï„ÅÑ „Çà „ÄÅ „Åò„ÇÉ „Å™„ÅÑ „Å® ÈÅÖÂàª „Åó „Å°„ÇÉ„ÅÜ „Åã„Çâ „Å≠ „ÄÇ\n",
            "Reference translation: get up early or you'll be late\n",
            "Translator output: come and see you i'm late\n",
            "BLEU Score: 3.46\n",
            "--------------------------------------------------------------------------------\n",
            "Example 3\n",
            "To be translated: ÂÉï „ÅØ ÈÉΩ‰ºö „ÅÆ ÁîüÊ¥ª Âêë„Åç „Å´ Âá∫Êù• „Å¶ „ÅÑ „Å™„ÅÑ „Å® ÊÄù„ÅÜ „ÄÇ\n",
            "Reference translation: i don't think that i'm cut out for city life\n",
            "Translator output: i don't think i could be able to live on the city\n",
            "BLEU Score: 9.06\n",
            "--------------------------------------------------------------------------------\n",
            "Example 4\n",
            "To be translated: ‰∏çÂÆâ „Å† „ÄÇ\n",
            "Reference translation: i'm feeling nervous\n",
            "Translator output: i am hungry\n",
            "BLEU Score: 0.00\n",
            "--------------------------------------------------------------------------------\n",
            "Example 5\n",
            "To be translated: ‰ªäÂ§ú „ÅØ Â§ñÈ£ü „Åó „Åü„Åè „Å™„ÅÑ „ÄÇ\n",
            "Reference translation: i don't feel like eating out this evening\n",
            "Translator output: i don't want to eat out tonight\n",
            "BLEU Score: 6.70\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "You've hit the end of Notebook 3. üòä What do you think Attention did to the model? \n",
            "Are we getting better or worse translations? What about the BLEU scores? \n",
            "In the next notebook, we will replace our LSTM layers with a Transformer.\n",
            "ps. For additional reading on BLEU score, check out this blog:\n",
            "https://bricksdont.github.io/posts/2020/12/computing-and-reporting-bleu-scores\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "* This is the third notebook for my sequence-to-sequence Neural Machine Translation (NMT) project.\n",
        "* The primary goal of this particular notebook is to compare the LSTM encoder-decoder model's performance with and without attention mechanism.\n",
        "* To learn more about the attention used, check out the paper: Luong et al, Effective Approaches to Attention-based Neural Machine Translation.\n",
        "* To run this notebook, modify the save_dir path below just like in notebook 2 (NMT with simple LSTM).\n",
        "* The next notebook in this series will be \"4.NMT with Transformer\".\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ================== config ==================\n",
        "batch_size = 64\n",
        "embedding_dim = 128\n",
        "hidden_size = 128\n",
        "epochs = 15\n",
        "save_dir = '/content/gdrive/My Drive/NMT_Data'  # directory for saved data\n",
        "model_save_dir = os.path.join(save_dir, 'NMT_Models/LSTM_with_attention')  # directory for saving the trained models\n",
        "# ============================================\n",
        "\n",
        "# Mount Google Drive\n",
        "def mount_drive():\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "\n",
        "# Load the data and tokenizers that were generated in the Data Prep notebook\n",
        "def load_data_and_tokenizers(save_dir):\n",
        "  padded_en = np.load(os.path.join(save_dir, 'padded_english.npy'))\n",
        "  padded_ja = np.load(os.path.join(save_dir, 'padded_japanese.npy'))\n",
        "  with open(os.path.join(save_dir, 'english_tokenizer.pkl'), 'rb') as f:\n",
        "    en_tok = pickle.load(f)\n",
        "  with open(os.path.join(save_dir, 'japanese_tokenizer.pkl'), 'rb') as f:\n",
        "    ja_tok = pickle.load(f)\n",
        "  vocab_size_en = len(en_tok.word_index)\n",
        "  vocab_size_ja = len(ja_tok.word_index)\n",
        "  return padded_en, padded_ja, en_tok, ja_tok, vocab_size_en, vocab_size_ja\n",
        "\n",
        "# Split into train/val/test and create datasets\n",
        "def prepare_datasets(padded_en, padded_ja):\n",
        "  train_ja, temp_ja, train_en, temp_en = train_test_split(padded_ja, padded_en, test_size=0.30, random_state=42)\n",
        "  val_ja, test_ja, val_en, test_en = train_test_split(temp_ja, temp_en, test_size=2/3, random_state=42)\n",
        "  def make_dataset(x, y):\n",
        "    return tf.data.Dataset.from_tensor_slices((x, y)).shuffle(len(x)).batch(batch_size)\n",
        "  return (\n",
        "    make_dataset(train_ja, train_en),\n",
        "    make_dataset(val_ja, val_en),\n",
        "    make_dataset(test_ja, test_en),\n",
        "    train_ja, train_en, val_ja, val_en, test_ja, test_en\n",
        "  )\n",
        "\n",
        "# Define the encoder (with the encoder mask)\n",
        "class encoder_attention(Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
        "    super(encoder_attention, self).__init__()\n",
        "    self.embedding = Embedding(vocab_size + 1, embedding_dim, mask_zero=True)\n",
        "    self.lstm = LSTM(hidden_size, return_sequences=True, return_state=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.embedding(inputs)\n",
        "    encoder_mask = self.embedding.compute_mask(inputs)\n",
        "    encoder_out, encoder_h, encoder_c = self.lstm(x, mask=encoder_mask)\n",
        "    return encoder_out, encoder_h, encoder_c, encoder_mask\n",
        "\n",
        "# Define the decoder (with attention)\n",
        "class decoder_attention(Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
        "    super(decoder_attention, self).__init__()\n",
        "    self.embedding = Embedding(vocab_size + 1, embedding_dim, mask_zero=True)\n",
        "    self.lstm = LSTM(hidden_size, return_sequences=True, return_state=True)\n",
        "    self.W_a = Dense(hidden_size, use_bias=False)  # attention score projection\n",
        "    self.W_c = Dense(hidden_size, activation='tanh')  # combine context and hidden state\n",
        "    self.dense = Dense(vocab_size + 1)\n",
        "\n",
        "  def call(self, inputs, encoder_out, encoder_mask, initial_state=None):\n",
        "    x = self.embedding(inputs)\n",
        "    lstm_out, state_h, state_c = self.lstm(x, initial_state=initial_state)\n",
        "\n",
        "    # projection for encoder output and dot it with decoder lstm output to find attention scores\n",
        "    W_a_h = self.W_a(encoder_out)\n",
        "    scores = tf.matmul(lstm_out, W_a_h, transpose_b=True)       # scores = (batch_size, dec_seq_len, enc_seq_len)\n",
        "\n",
        "    # apply masking\n",
        "    encoder_mask = tf.cast(encoder_mask, tf.float32)\n",
        "    encoder_mask = tf.expand_dims(encoder_mask, axis=1)         # encoder_mask = (batch_size, 1, enc_seq_len)\n",
        "    mask_add = (1.0 - encoder_mask) * -1e9\n",
        "    scores += mask_add\n",
        "\n",
        "    # compute attention weights\n",
        "    attention_weights = tf.nn.softmax(scores, axis=-1)          # attention_weights= (batch_size, dec_seq_len, enc_seq_len)\n",
        "\n",
        "    # find the context vector which is a weighted sum of the encoder output at each time step\n",
        "    context_vector = tf.matmul(attention_weights, encoder_out)  # (batch_size, dec_seq_len, enc_seq_len) * (batch_size, enc_seq_len, hidden_size)\n",
        "    # context vector = (batch_size, dec_seq_len, encoder_hidden_size)\n",
        "\n",
        "    # concat the context vector with LSTM output\n",
        "    combined = tf.concat([context_vector, lstm_out], axis=-1)   # combined = (batch_size, dec_seq_len, decoder_hidden_size + encoder_hidden_size)\n",
        "\n",
        "    # project combined back to hidden_size\n",
        "    combined_projected = self.W_c(combined)                     # combined_projected = (batch_size, dec_seq_len, hidden_size)\n",
        "\n",
        "    logits = self.dense(combined_projected)\n",
        "    return logits, state_h, state_c\n",
        "\n",
        "# Define loss function\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "# Prepare training data and label for the decoder\n",
        "def prepare_decoder(target_batch):\n",
        "  decoder_input = target_batch[:, :-1]\n",
        "  decoder_target = target_batch[:, 1:]\n",
        "  return decoder_input, decoder_target\n",
        "\n",
        "# Forward and backward pass (calculate gradients for encoder and decoder together)\n",
        "@tf.function\n",
        "def grad(encoder, decoder, Japanese_input, decoder_input_english, ground_truth_english):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # send inputs into encoder, then create encoder_mask. use the states to set up the decoder\n",
        "    encoder_out, hidden_state, cell_state, encoder_mask = encoder(Japanese_input)\n",
        "    decoder_output, _, _ = decoder(decoder_input_english, encoder_out, encoder_mask, initial_state=[hidden_state, cell_state])\n",
        "\n",
        "    # masked loss calculation\n",
        "    mask = tf.cast(ground_truth_english != 0, dtype=tf.float32)\n",
        "    loss_per_token = loss_object(ground_truth_english, decoder_output)\n",
        "    masked_loss = loss_per_token * mask\n",
        "    loss_value = tf.reduce_sum(masked_loss) / tf.reduce_sum(mask)\n",
        "\n",
        "    # get gradients over the parameters from both encoder and decoder\n",
        "    trainable_vars = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss_value, trainable_vars)\n",
        "\n",
        "    return loss_value, gradients\n",
        "\n",
        "# Custom training loop (train encoder and decoder together)\n",
        "def custom_training(num_epochs, train_dataset, val_dataset, encoder, decoder, optimizer, model_save_dir=None):\n",
        "  train_loss_results = []\n",
        "  val_loss_results = []\n",
        "  best_val_loss = float('inf')\n",
        "  best_encoder_weights = None\n",
        "  best_decoder_weights = None\n",
        "  best_epoch = -1\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "    val_loss_avg = tf.keras.metrics.Mean()\n",
        "    start_time = tf.timestamp()\n",
        "\n",
        "    # training loop\n",
        "    for japanese_input, english_input in train_dataset:\n",
        "      decoder_input_english, ground_truth_english = prepare_decoder(english_input)\n",
        "      loss_value, grads = grad(encoder, decoder, japanese_input, decoder_input_english, ground_truth_english)\n",
        "      trainable_vars = encoder.trainable_variables + decoder.trainable_variables\n",
        "      optimizer.apply_gradients(zip(grads, trainable_vars))\n",
        "      epoch_loss_avg(loss_value)\n",
        "\n",
        "    # validation loop\n",
        "    for japanese_input, english_input in val_dataset:\n",
        "      decoder_input_english, ground_truth_english = prepare_decoder(english_input)\n",
        "      val_loss_value, _ = grad(encoder, decoder, japanese_input, decoder_input_english, ground_truth_english)\n",
        "      val_loss_avg(val_loss_value)\n",
        "\n",
        "    train_loss = epoch_loss_avg.result()\n",
        "    val_loss = val_loss_avg.result()\n",
        "    train_loss_results.append(train_loss)\n",
        "    val_loss_results.append(val_loss)\n",
        "\n",
        "    # save the temporary best model weights\n",
        "    if val_loss < best_val_loss:\n",
        "      best_val_loss = val_loss\n",
        "      best_encoder_weights = encoder.get_weights()\n",
        "      best_decoder_weights = decoder.get_weights()\n",
        "      best_epoch = epoch + 1\n",
        "\n",
        "    # epoch summary\n",
        "    epoch_time = (tf.timestamp() - start_time) / 60\n",
        "    print(f\"Epoch {epoch+1}, Training Loss {train_loss:.4f}, Validation Loss {val_loss:.4f}, Time: {epoch_time:.2f} min\")\n",
        "\n",
        "  # load best models\n",
        "  encoder.set_weights(best_encoder_weights)\n",
        "  decoder.set_weights(best_decoder_weights)\n",
        "  print(f\"Training completed. Best model from epoch {best_epoch} with Validation Loss = {best_val_loss:.4f}\")\n",
        "\n",
        "  # save the final best model after training is completed\n",
        "  if model_save_dir:\n",
        "    os.makedirs(model_save_dir, exist_ok=True)\n",
        "    encoder_path = os.path.join(model_save_dir, 'best_encoder.weights.h5')\n",
        "    decoder_path = os.path.join(model_save_dir, 'best_decoder.weights.h5')\n",
        "    encoder.save_weights(encoder_path)\n",
        "    decoder.save_weights(decoder_path)\n",
        "    print(f\"Best model saved to: {model_save_dir}\")\n",
        "\n",
        "  return train_loss_results, val_loss_results\n",
        "\n",
        "# Plot training progress with perplexity\n",
        "def plot_perplexity(train_loss, val_loss, epochs):\n",
        "  train_perplexity = np.exp(train_loss)\n",
        "  val_perplexity = np.exp(val_loss)\n",
        "  plt.figure(figsize=(5, 3))\n",
        "  plt.plot(range(1, len(train_perplexity)+1), train_perplexity, label='train', linestyle='dotted', color='blue')\n",
        "  plt.plot(range(1, len(val_perplexity)+1), val_perplexity, label='val', linestyle='solid', color='blue')\n",
        "  plt.xticks(range(1, epochs+1))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Perplexity')\n",
        "  plt.legend()\n",
        "  plt.title(\"Perplexity Vs. Epoch\")\n",
        "  plt.show()\n",
        "\n",
        "# Evluation on test dataset\n",
        "def evaluate_on_test(test_dataset, encoder, decoder):\n",
        "  test_loss_avg = tf.keras.metrics.Mean()\n",
        "  for japanese_input, english_input in test_dataset:\n",
        "    decoder_input_english, ground_truth_english = prepare_decoder(english_input)\n",
        "    test_loss_value, _ = grad(encoder, decoder, japanese_input, decoder_input_english, ground_truth_english)\n",
        "    test_loss_avg(test_loss_value)\n",
        "  print(\"\\nTest Loss: {:.4f}\".format(test_loss_avg.result()))\n",
        "  print(\"Perplexity: {:.4f}\".format(np.exp(test_loss_avg.result())))\n",
        "\n",
        "# Build a translator class\n",
        "class Translator(tf.Module):\n",
        "  def __init__(self, ja_tok, en_tok, encoder, decoder, start_token='start', end_token='end', max_tokens=100):\n",
        "    self.ja_tok = ja_tok\n",
        "    self.en_tok = en_tok\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.start_token = start_token\n",
        "    self.end_token = end_token\n",
        "    self.start_token_id = en_tok.word_index[start_token]\n",
        "    self.end_token_id = en_tok.word_index[end_token]\n",
        "    self.max_tokens = max_tokens\n",
        "\n",
        "  def __call__(self, sentence):\n",
        "    # convert input sentence from str to list\n",
        "    if isinstance(sentence, str):\n",
        "      sentence = [sentence]\n",
        "\n",
        "    # prepare the Japanese sentence and pass it through the encoder\n",
        "    encoder_input = self.ja_tok.texts_to_sequences(sentence)\n",
        "    encoder_input = tf.keras.preprocessing.sequence.pad_sequences(encoder_input, padding='post')\n",
        "    encoder_input = tf.convert_to_tensor(encoder_input)\n",
        "    encoder_out, hidden_state, cell_state, encoder_mask = self.encoder(encoder_input)\n",
        "\n",
        "    # initialize output tensor for Decoder\n",
        "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
        "    output_array = output_array.write(0, tf.constant([self.start_token_id], dtype=tf.int64))\n",
        "    h, c = hidden_state, cell_state # use the encoder's final h_state and c_state as the initial states of the decoder\n",
        "\n",
        "    # generation\n",
        "    for i in tf.range(self.max_tokens):\n",
        "      current_output = tf.transpose(output_array.stack())  # a list of tokens\n",
        "      current_token = current_output[:, -1:]  # get the last token\n",
        "\n",
        "      # feed last token into decoder to get prediction for the next one\n",
        "      logits, h, c = self.decoder(current_token, encoder_out, encoder_mask, initial_state=[h, c])\n",
        "      predicted_id = tf.argmax(logits[:, -1:, :], axis=-1)\n",
        "      output_array = output_array.write(i + 1, predicted_id[0])\n",
        "\n",
        "      # check for end token\n",
        "      if predicted_id[0][0].numpy() == self.end_token_id:\n",
        "        break\n",
        "\n",
        "    output = tf.transpose(output_array.stack())  # shape: (1, seq_len)\n",
        "    output_tokens = output.numpy()[0]\n",
        "\n",
        "    # convert token ids back to words\n",
        "    index_word = self.en_tok.index_word\n",
        "    translated_tokens = [index_word.get(id, '') for id in output_tokens if id != 0]\n",
        "    translated_text = ' '.join(translated_tokens[1:-1])  # skip <start> and <end> for readability\n",
        "    return translated_text, translated_tokens\n",
        "\n",
        "# Calculate BLEU score for translated text\n",
        "def rate_bleu_score(reference_text, translated_text, weights=(0.25, 0.25, 0.25, 0.25)):\n",
        "  smoother = SmoothingFunction().method1\n",
        "  reference_tokens = reference_text.split()\n",
        "  candidate_tokens = translated_text.split()\n",
        "  bleu_score = sentence_bleu([reference_tokens], candidate_tokens, weights=weights, smoothing_function=smoother)\n",
        "  return bleu_score\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "  print(\"=\" * 80)\n",
        "  print(\"Running Notebook No.3 to build a LSTM NMT with Attention.\")\n",
        "  print(\"=\" * 80)\n",
        "\n",
        "  # Mount Google Drive\n",
        "  print(\"\\n1. Mounting Google Drive...\")\n",
        "  mount_drive()\n",
        "\n",
        "  # Load data from Drive\n",
        "  print(\"\\n2. Loading tokenizers and padded data...\")\n",
        "  padded_en, padded_ja, en_tok, ja_tok, vocab_size_en, vocab_size_ja = load_data_and_tokenizers(save_dir)\n",
        "  print(\"Done.\")\n",
        "\n",
        "  # Split data\n",
        "  print(\"\\n3. Splitting data into training (70%), validation (10%), and test (20%) sets...\")\n",
        "  train_ds, val_ds, test_ds, train_ja, train_en, val_ja, val_en, test_ja, test_en = prepare_datasets(padded_en, padded_ja)\n",
        "  print(\"Done.\")\n",
        "\n",
        "  # Initialize encoder, decoder, and optimizer\n",
        "  print(\"\\n4. Initializing encoder and decoder models with attention...\")\n",
        "  encoder = encoder_attention(vocab_size_ja, embedding_dim, hidden_size)\n",
        "  decoder = decoder_attention(vocab_size_en, embedding_dim, hidden_size)\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "  sample_ja, sample_en = next(iter(train_ds))\n",
        "  dec_input, _ = prepare_decoder(sample_en)\n",
        "  enc_out, h, c, mask = encoder(sample_ja)\n",
        "  _ = decoder(dec_input, enc_out, mask, initial_state=[h, c])\n",
        "  print(\"Done.\")\n",
        "\n",
        "  # Train model\n",
        "  print(\"\\n5. Model training...\")\n",
        "  train_loss, val_loss = custom_training(epochs, train_ds, val_ds, encoder, decoder, optimizer, model_save_dir=model_save_dir)\n",
        "  plot_perplexity(train_loss, val_loss, epochs)\n",
        "  print(\"Evaluating model performance on test data...\")\n",
        "  evaluate_on_test(test_ds, encoder, decoder)\n",
        "\n",
        "  # Create translator instance\n",
        "  print(\"\\n6. Creating a translator instance with the trained encoder and decoder (with attention)...\")\n",
        "  os.system('apt install -y mecab mecab-ipadic-utf8') # installing MeCab\n",
        "  os.system('pip install mecab-python3 unidic-lite')\n",
        "  translator = Translator(ja_tok, en_tok, encoder, decoder, start_token='start', end_token='end', max_tokens=padded_en.shape[1])\n",
        "  print(\"Done.\")\n",
        "\n",
        "  # Test translation on some examples\n",
        "  print(\"\\n7. Let's use the translator on a few examples...\")\n",
        "  indice_chosen = [10, 20, 30, 40, 50]\n",
        "  for i, indice in enumerate(indice_chosen, 1):\n",
        "    japanese_test = ja_tok.sequences_to_texts([test_ja[indice]])[0].replace('start', '').replace('end', '').strip()\n",
        "    reference_translation = en_tok.sequences_to_texts([test_en[indice]])[0].replace('start', '').replace('end', '').strip()\n",
        "    print('Example', i)\n",
        "    print('To be translated:', japanese_test)\n",
        "    print('Reference translation:', reference_translation)\n",
        "\n",
        "    # call translator\n",
        "    translated_text, translated_tokens = translator(japanese_test)\n",
        "    print('Translator output:', translated_text)\n",
        "\n",
        "    # calculate BLEU score\n",
        "    bleu_score = rate_bleu_score(reference_translation, translated_text)\n",
        "    print(f'BLEU Score: {bleu_score * 100:.2f}') # note BLEU is usually reported in range 0-100, but it is not a percentage.\n",
        "    print('-' * 80)\n",
        "\n",
        "  print(\"\\n\" + \"=\" * 80)\n",
        "  print(\"You've hit the end of Notebook 3. üòä What do you think Attention did to the model? \")\n",
        "  print(\"Are we getting better or worse translations? What about the BLEU scores? \")\n",
        "  print(\"In the next notebook, we will replace our LSTM layers with a Transformer.\")\n",
        "  print(\"ps. For additional reading on BLEU score, check out this blog:\")\n",
        "  print(\"https://bricksdont.github.io/posts/2020/12/computing-and-reporting-bleu-scores\")\n",
        "  print(\"=\" * 80)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YMcvspqbAIkD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}